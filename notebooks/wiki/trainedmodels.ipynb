{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "glinert_with_combinations_params = {\n",
    "    'n_estimators': 200,\n",
    "    'learning_rate': 0.005102526970639764,\n",
    "    'max_depth': 2,\n",
    "    'subsample': 0.9802199511834219,\n",
    "    'colsample_bytree': 0.5040893101729162,\n",
    "    'min_child_weight': 2\n",
    "}\n",
    "\n",
    "glinert_without_combinations_params = {\n",
    "    'C': 4313419626880376,\n",
    "    'fit_intercept': True,\n",
    "    'solver': 'liblinear',\n",
    "    'max_iter': 905,\n",
    "    'penalty': 'l1'\n",
    "}\n",
    "\n",
    "blau_with_combinations_params = {\n",
    "    'n_estimators': 214,\n",
    "    'learning_rate': 0.08413767421235069,\n",
    "    'max_depth': 2,\n",
    "    'subsample': 0.8509639676276632,\n",
    "    'colsample_bytree': 0.9536060098203626,\n",
    "    'min_child_weight': 1\n",
    "    \n",
    "}\n",
    "\n",
    "blau_without_combinations_params =  {\n",
    "    'shrink_threshold': 0.06913327679322363\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_train(method, comb = False):\n",
    "    filename = f'merged_comb_{method}.xlsx'\n",
    "    if comb:\n",
    "        df = pd.read_excel(os.path.join('../excel', f'merged_comb_{method}.xlsx'))\n",
    "    else:\n",
    "        df = pd.read_excel(os.path.join('../excel', f'merged_{method}.xlsx'))\n",
    "    df.replace({None: pd.NA}, inplace=True)\n",
    "    df.drop(columns=['target word_0'], inplace=True)\n",
    "    df.dropna(subset=[method.capitalize()], inplace=True)\n",
    "    df = df[df[method.capitalize()] != '-']\n",
    "    df.fillna('', inplace=True)\n",
    "\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "\n",
    "    encoder = OneHotEncoder(sparse=False , handle_unknown='ignore')\n",
    "    X = X.astype(str)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    encoder.fit(X_train)\n",
    "    X_train = encoder.transform(X_train)\n",
    "    X_test = encoder.transform(X_test)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train = label_encoder.fit_transform(y_train)\n",
    "    y_test = label_encoder.fit_transform(y_test)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized mean: 0.5242718446601944\n",
      "not optimized mean: 0.4854368932038836\n",
      "glinert with combinations=True is better with optimization\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.07      0.09        14\n",
      "           1       0.52      0.68      0.59        41\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.62      0.60      0.61        42\n",
      "\n",
      "    accuracy                           0.52       103\n",
      "   macro avg       0.25      0.27      0.26       103\n",
      "weighted avg       0.48      0.52      0.50       103\n",
      "\n",
      "optimized mean: 0.5339805825242719\n",
      "not optimized mean: 0.5339805825242719\n",
      "glinert with combinations=False is better without optimization\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.29      0.24        14\n",
      "           1       0.56      0.68      0.62        41\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.70      0.55      0.61        42\n",
      "\n",
      "    accuracy                           0.53       103\n",
      "   macro avg       0.29      0.30      0.29       103\n",
      "weighted avg       0.53      0.53      0.53       103\n",
      "\n",
      "optimized mean: 0.6601941747572815\n",
      "not optimized mean: 0.6893203883495146\n",
      "blau with combinations=True is better without optimization\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.20      0.33         5\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.65      0.93      0.77        55\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.79      0.49      0.60        39\n",
      "\n",
      "    accuracy                           0.69       103\n",
      "   macro avg       0.49      0.32      0.34       103\n",
      "weighted avg       0.70      0.69      0.65       103\n",
      "\n",
      "optimized mean: 0.436893203883495\n",
      "not optimized mean: 0.436893203883495\n",
      "blau with combinations=False is better without optimization\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.07      0.33      0.11         3\n",
      "           2       0.57      0.53      0.55        55\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.47      0.38      0.42        39\n",
      "\n",
      "    accuracy                           0.44       103\n",
      "   macro avg       0.22      0.25      0.22       103\n",
      "weighted avg       0.48      0.44      0.46       103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def test_optimization():\n",
    "    methods = {\n",
    "        ('glinert', True): (XGBClassifier , glinert_with_combinations_params),\n",
    "        ('glinert', False): (LogisticRegression, glinert_without_combinations_params),\n",
    "        ('blau', True): (XGBClassifier, blau_with_combinations_params),\n",
    "        ('blau', False): (NearestCentroid, blau_without_combinations_params)\n",
    "    }\n",
    "\n",
    "    for method in methods:\n",
    "        result = {'optimized':[], 'not_optimized':[]}\n",
    "        for _ in range(25):\n",
    "            X_train, X_test, y_train, y_test = test_train(method[0], method[1])\n",
    "            opt_model = methods[method][0](**methods[method][1])\n",
    "            opt_model.fit(X_train, y_train)\n",
    "            y_pred_opt = opt_model.predict(X_test)\n",
    "            result['optimized'].append(accuracy_score(y_test, y_pred_opt))\n",
    "            not_opt_model = methods[method][0]()\n",
    "            not_opt_model.fit(X_train, y_train)\n",
    "            y_pred = not_opt_model.predict(X_test)\n",
    "            result['not_optimized'].append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "        optmized_mean = sum(result['optimized'])/len(result['optimized'])\n",
    "        not_optimized_mean = sum(result['not_optimized'])/len(result['not_optimized'])\n",
    "\n",
    "        print (f'optimized mean: {optmized_mean}')\n",
    "        print (f'not optimized mean: {not_optimized_mean}')\n",
    "\n",
    "        if optmized_mean > not_optimized_mean:\n",
    "            print(f'{method[0]} with combinations={method[1]} is better with optimization')\n",
    "            print(classification_report(y_test, y_pred_opt))\n",
    "            \n",
    "        else:\n",
    "            print(f'{method[0]} with combinations={method[1]} is better without optimization')\n",
    "            print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "test_optimization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see,\n",
    "For Glinert, it's best to not use the combinations and there is no difference between the hyperparameter tuning approach and the default one\n",
    "For Blau, it's best to use the combinations and without Optuna's tuning.\n",
    "\n",
    "Now we will train the whole dataset with the best model for each approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoded_dataset(method, comb=True):\n",
    "    excel_folder = '../excel'\n",
    "    if comb:\n",
    "        df = pd.read_excel(os.path.join(excel_folder,f'merged_comb_{method}.xlsx'))\n",
    "    else:\n",
    "        df = pd.read_excel(os.path.join(excel_folder,f'merged_{method}.xlsx'))\n",
    "    df.replace({None: pd.NA}, inplace=True)\n",
    "    df.drop(columns=['target word_0'], inplace=True)\n",
    "    df.dropna(subset=[method.capitalize()], inplace=True)\n",
    "    df = df[df[method.capitalize()] != '-']\n",
    "    df.fillna('', inplace=True)\n",
    "\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "\n",
    "    encoder = OneHotEncoder(sparse=False , handle_unknown='ignore')\n",
    "    X = X.astype(str)\n",
    "    encoder.fit(X)\n",
    "    X = encoder.transform(X)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model for glinert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=4313419626880376, max_iter=905, penalty=&#x27;l1&#x27;,\n",
       "                   solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=4313419626880376, max_iter=905, penalty=&#x27;l1&#x27;,\n",
       "                   solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=4313419626880376, max_iter=905, penalty='l1',\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glinert_final_model = LogisticRegression(**glinert_without_combinations_params)\n",
    "X, y = encoded_dataset('glinert')\n",
    "glinert_final_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model for Blau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective='multi:softprob', predictor=None, ...)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blau_final_model = XGBClassifier()\n",
    "X, y = encoded_dataset('blau')\n",
    "blau_final_model.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
