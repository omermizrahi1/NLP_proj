<!-----

Yay, no errors, warnings, or alerts!

Conversion time: 0.449 seconds.


Using this Markdown file:

1. Paste this output into your source file.
2. See the notes and action items below regarding this conversion run.
3. Check the rendered output (headings, lists, code blocks, tables) for proper
   formatting and use a linkchecker before you publish this page.

Conversion notes:

* Docs to Markdown version 1.0β34
* Fri Aug 04 2023 07:24:14 GMT-0700 (PDT)
* Source doc: NLP
----->


<p dir="rtl">
הוראות קריאת הפרויקט:</p>


<p dir="rtl">
הפרויקט יחולק לשני branches:</p>




1. Tanach_window
2. Wiki_window

<p dir="rtl">
כאשר בכל אחד מהענפים יהיו שתי מחברות יופיטר רלוונטיות:</p>




1. עבור קוד המודל, האימון והתוצאות - trainedmodels.ipynb.
2. עמוד סטטיסטיקות על המידע שניתחנו - datastatistics.ipynb.

<p dir="rtl">
סידור תיקיות:</p>


<p dir="rtl">
excel -  מכילה את כל ה-dataframes שעבדנו איתם בקבצי xlsx.</p>


<p dir="rtl">
logs - מכילה את הלוגים שיצאו מה hyperparameter tuning</p>


<p dir="rtl">
tanach - מכילה את קבצי התנ”ך XML אותם פירסרנו.</p>


<p dir="rtl">
wiki - מכילה את קבצי ה - conllu text שאותם פירסרנו.</p>


<p dir="rtl">
הבניין שבחרנו: <strong>נפעל</strong></p>


<p dir="rtl">
בחירת הטקסטים:</p>


<p dir="rtl">
כשעברנו על הטקסטים בשני הקורפוסים, ראינו שיש הרבה טקסטים מתחום המשפט, ולכן חשבנו לבחור טקסטים מקבילים מהתנ"ך שהם קשורים למשפט גם כן. בחרנו בטקסטים מהתורה ובפרט מספרי שמות, ויקרא, במדבר, כי שם יש טקסטים בעלי אופי משפטי – חוקים. </p>


<p dir="rtl">
בדיעבד לאחר משימת תיוג הטקסטים לדעתנו הבחירה בטקסטים אלו הייתה שגויה, משום שאם היינו בוחרים טקסטים יותר מגוונים היינו יכולים לקבל תוצאות טובות יותר באופן כללי מכלל התנ"ך, שכן בטקסטים שבחרנו מהתנ"ך יש פעלים רבים ותבניות שחוזרות על עצמן.</p>


<p dir="rtl">
עיבוד הטקסטים:</p>


<p dir="rtl">
כדי להתחיל במשימת התיוג היה עלינו לשלוף מהקורפוסים שבחרנו את הפעלים הרלוונטיים לפי הבניין שבחרנו.</p>


<p dir="rtl">
עשינו זאת בעזרת הסקריפטים tanachparser.py ו- wikiparser.py. </p>


<p dir="rtl">
בניית מדריך תיוג:</p>


<p dir="rtl">
בבניית מדריך התיוג נעזרנו בספרים של הבלשנים. ההסברים של גלינרט היה די ברור ומפורט עם דוגמאות ברורות, לעומת ההסברים של בלאו שהיו מעט פשטניים מדי לדעתנו. את מדריך התיוג ניתן לראות בקובץ tagging_manual.pdf.</p>


<p dir="rtl">
תיוג הדוגמאות: \
תחילה התיוג היה מאוד מבלבל, אך עם ההתקדמות זה בא יותר בקלות. שיטת התיוג של גלינרט הייתה יותר קלה וברורה מאשר של בלאו, החלוקה הייתה יותר הגיונית. כמו כן, בשני השיטות יש תיוגים שברובם היו חופפים (לדוגמא תיוג 5 בשני השיטות, תיוג 1 ו2 בגלינרט היה חופף לתיוג 3 בבלאו, ותיוג 4 בשני המקרים). כמו כן, כפי שנראה בסטטיסטיקות על ה-dataset, פיזור התיוג היה לא מאוזן בכלל. דבר שיכול להשפיע על תוצאות המסווג – נראה זאת בהמשך.</p>


<p dir="rtl">
סטטיסטיקות על ה - data:</p>


<p dir="rtl">
אספנו מספר סטטיסטיקות שיכולות ללמד אותנו על טיב ה- data שאספנו. את הסטטיסטיקות הללו ניתן למצוא במחברת datastatistics.ipynb בכל ענף.</p>


<p dir="rtl">
בניית וקטור הדוגמאות:</p>


<p dir="rtl">
החלטנו שכדי לקבל יותר מידע על הפעלים שברשותנו, אנחנו צריכים לדעת את הקונטקסט של כל פועל. לכן, כתבנו מתודות אשר בהינתן פועל  וגודל חלון, נותנות לנו את כל המילים שלפני ואחרי המילה כגודל החלון (לדוג', אם גודל החלון הוא 2, ניקח 2 מילים לפניה ו - 2 מילים אחריה במשפט).</p>


<p dir="rtl">
לכל פועל מכל הפעלים המתויגים, כתבנו את כל הנתונים הסינטקטיים והמורפולוגים לכל מילה אשר נמצאת בחלון.</p>


<p dir="rtl">
את נתוני הווקטור ניתן לראות בקובץ merged.xlsx.</p>


<p dir="rtl">
לאחר מכן החלטנו, שנשווה את הווקטורים שהוצאנו עם גודל החלון לשיפור נוסף שהוצע בהנחיות העבודה: קומבינציות בין המאפיינים השונים של כל מילה ולכן, הוספנו לכל וקטור הרכבים של מאפיינים עבור כל מילה בחלון. </p>


<p dir="rtl">
את ווקטורי המאפיינים האלה ניתן לראות בקבצים: merged_comb_blau.xlsx ו - merged_comb_glinert.xlsx.</p>


<p dir="rtl">
לאחר מכן, כאשר אימנו את המודל השתמשנו ב - <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html">OneHotEncoder</a> מספריית scikit-learn לקודד את ה - data, משום שהדאטה הוא ברובו קטגורי.</p>


<p dir="rtl">
בהמשך נראה שהווקטור בעל ההרכבים של קומבינציות המאפיינים קיבל תוצאות טובות יותר במקצת.</p>


<p dir="rtl">
את פונקציונליות זו ניתן לראות בקבצים pds.py, feature_vector.py.</p>


<p dir="rtl">
בעיה שצצה לנו תוך כדי היא שרצינו לאחד את שני ה - datasets, אך המאפיינים הסינטקטיים של שני המאגרים מתויגים באופן שונה מה שהקשה על ההשוואה בין השניים. </p>


<p dir="rtl">
שימוש במאפיינים הסינטקטיים נותן מידע רב על הקונטקסט של הפועל עליו נרצה לעשות קלסיפקציה. אם, למשל, היה לנו את התנ"ך מתוייג בפורמט conllu, דבר זה היה מתאפשר. לכן החלטנו לפצל את הדאטסטים ולהכין 2 מודלים, אחד לכל גישת תיוג לכל קורפוס. </p>


<p dir="rtl">
כמו כן, חששנו שסגנון הכתיבה השונה "יבלבל" את המודל וישפיע לרעה על תוצאות הסיווג. לכן, לבסוף החלטנו להפריד בין שני הקורפוסים.</p>


<p dir="rtl">
אימון המסווג:</p>


<p dir="rtl">
תחילה הפרדנו את ה - data למדגם אימון ומדגם מבחן (train, test). לאחר מכן השתמשנו בספרייה <a href="https://lazypredict.readthedocs.io/en/latest/usage.html#classification">Lazy Predict</a> כדי לבחור את המודל עם מדד ה - accuracy הגבוה ביותר על מדגם ה - test. את התוצאות ניתן לראות בקובץ lazypredict_results.txt שבתיקיית logs.</p>


<p dir="rtl">
קורפוס התנ"ך</p>




* עבור גלינרט ללא הרכב מאפיינים המודל הכי טוב שקיבלנו הוא [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).
* עבור בלאו ללא הרכב מאפיינים המודל הכי טוב שקיבלנו הוא [XGBoost](https://xgboost.readthedocs.io/en/stable/).
* עבור גלינרט עם הרכב מאפיינים המודל הכי טוב שקיבלנו הוא [Extra Trees](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html).
* עבור בלאו עם הרכב מאפיינים המודל הכי טוב שקיבלנו הוא [Extra Trees](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html).

<p dir="rtl">
קורפוס ויקיפדיה העברית</p>




* עבור גלינרט ללא הרכב מאפיינים המודל הכי טוב שקיבלנו הוא.
* עבור בלאו ללא הרכב מאפיינים המודל הכי טוב שקיבלנו הוא 
* עבור גלינרט עם הרכב מאפיינים המודל הכי טוב שקיבלנו הוא 
* עבור בלאו עם הרכב מאפיינים המודל הכי טוב שקיבלנו הוא

<p dir="rtl">
לאחר מכן החלטנו לקחת את המודל שהניב את המדדים הכי טובים בכל גישה, ולעשות לו hyperparameters tuning ו- 10 fold cross validation. זאת עשינו בעזרת ספריית <a href="https://optuna.org/">Optuna</a>, המשמשת לאופטימיזציה של היפר פרמטרים, תוך שימוש באופטימיזציה מבוססת SMBO כדי לחפש ביעילות את ערכי הhyperparameters הטובים ביותר. את תוצאות ההרצה ניתן לראות בקבצי הלוגים אשר נמצאים בתיקיית logs.</p>


<p dir="rtl">
לאחר הרצת optuna רצינו לבדוק האם באמת ה Hyperparameter tuning  נתנה לנו תוצאות טובות. הרצנו את המתודה test_optimiztion אשר נמצאת במחברת trainedmodel.ipynb. ניתן לראות שעבור המודלים שאימנו על קורפוס התנ"ך היה שיפור, אם כי שיפור מינורי. <strong>להשלים על ויקי.</strong></p>


<p dir="rtl">
תוצאות:</p>


<p dir="rtl">
אפשר לראות שהתוצאות שקיבלנו לא מדהימות. הנה כמה סיבות אפשריות לכך:</p>




* דאטה סט קטן מידי – 500~ דוגמאות זה מספר מעט מידי של דוגמאות.
* דוגמאות לא מאוזנות. כפי שניתן לראות בסטטיסטיקות שהוצאנו על ה - data, לכל גישה יש 2 תיוגים שמהוות את רוב התיוגים בעוד שיש תיוגים שכמעט ולא מופיעים.
* תיוגים לא נכונים – שיטת התיוג היא מבלבלת ואינה חד משמעית לכן, איכות הסיווג הוא בסימן שאלה מהסיבה העיקרית שאין לנו ניסיון כבלשנים לסווג מידע ולכן ישנה סבירות שטעינו בחלק מהתיוגים.
